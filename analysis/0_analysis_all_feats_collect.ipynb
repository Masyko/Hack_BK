{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f0f70a",
   "metadata": {},
   "source": [
    "### Сборка всех фичей\n",
    "\n",
    "Сборка всех признаков, которые разработали и подсчет information value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ea7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03542f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_92453/437858164.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML, clear_output\n",
      "/tmp/ipykernel_92453/437858164.py:1: DeprecationWarning: Importing clear_output from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML, clear_output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.prompt { min-width:10ex !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML, clear_output\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "display(HTML(\"<style>.prompt { min-width:10ex !important; }</style>\"))\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cafb3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet('../data/train_dataset_hackaton2023_train.gzip')\n",
    "df_test = pd.read_parquet('../data/test_dataset_hackaton2023_test.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84953ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std_feats(dataset, ids_cols):\n",
    "    df_sum_agg = dataset.groupby(ids_cols, as_index=True).agg({\"revenue\": [\"sum\", \"count\"]})\n",
    "    df_sum_agg.columns = [\"revenue_sum\", \"items_count\"]\n",
    "    df_sum_agg.reset_index(inplace=True)\n",
    "    new_ids_cols = list(set(ids_cols).difference([\"startdatetime\"]))\n",
    "    df_by_customer_data = (\n",
    "        df_sum_agg\n",
    "        .groupby(new_ids_cols)\n",
    "        .agg({\n",
    "            \"revenue_sum\": ['mean', 'std', 'count'],\n",
    "            \"items_count\": ['mean', 'std'],\n",
    "        }).reset_index()\n",
    "    )\n",
    "    df_by_customer_data.columns = new_ids_cols + [\n",
    "        'receipt_sum_mean', \n",
    "        'receipt_sum_std',\n",
    "        'receipt_count', \n",
    "        'items_receipt_mean',\n",
    "        'items_receipt_mean_std',\n",
    "    ]\n",
    "    return df_by_customer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e958f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dynamic_receipt_features(dataframe, ids_cols):\n",
    "    df_sum_agg = dataframe.groupby(ids_cols, as_index=True).agg({\"revenue\": [\"sum\", \"count\"]})\n",
    "    df_sum_agg.columns = [\"revenue_sum\", \"items_count\"]\n",
    "    df_sum_agg.reset_index(inplace=True)\n",
    "    df_sum_agg = df_sum_agg.sort_values(by=ids_cols)\n",
    "    df_sum_agg[\"lag_sum\"] = df_sum_agg.groupby(['customer_id'])['revenue_sum'].shift(1)\n",
    "    df_sum_agg[\"lag_count\"] = df_sum_agg.groupby(['customer_id'])['items_count'].shift(1)\n",
    "    df_sum_agg[\"sum_delta\"] = df_sum_agg[\"revenue_sum\"] - df_sum_agg[\"lag_sum\"]\n",
    "    df_sum_agg[\"count_delta\"] = df_sum_agg[\"items_count\"] - df_sum_agg[\"lag_count\"]\n",
    "    new_ids_cols = list(set(ids_cols).difference([\"startdatetime\"]))\n",
    "    df_by_customer_data = (\n",
    "        df_sum_agg\n",
    "        .groupby(new_ids_cols, as_index=False)\n",
    "        .agg({\n",
    "            \"sum_delta\": [\"min\", \"max\", \"mean\", \"std\"], \n",
    "            \"count_delta\": [\"min\", \"max\", \"mean\", \"std\"], \n",
    "        })\n",
    "    )\n",
    "    df_by_customer_data.columns = new_ids_cols + [\n",
    "        f\"{col}_{agg_func}\" for col in [\"sum_delta\", \"count_delta\"]\n",
    "        for agg_func in [\"min\", \"max\", \"mean\", \"std\"]\n",
    "    ]\n",
    "    df_by_customer_data[\"abs_sum_delta_mean\"] = df_by_customer_data[\"sum_delta_mean\"].abs()\n",
    "    df_by_customer_data[\"abs_count_delta_mean\"] = df_by_customer_data[\"count_delta_mean\"].abs()\n",
    "    return df_by_customer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16afad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_window_features(dataset, ids_cols, windows):\n",
    "    df_sum_agg = dataset.groupby(ids_cols, as_index=True).agg({\"revenue\": [\"sum\", \"count\"]})\n",
    "    df_sum_agg.columns = [\"revenue_sum\", \"items_count\"]\n",
    "    df_sum_agg.reset_index(inplace=True)\n",
    "    \n",
    "    df_max_dt = df_sum_agg.groupby(['customer_id'], as_index=False).agg({\"startdatetime\": [\"max\"]})\n",
    "    df_max_dt.columns = [\"customer_id\", \"max_startdatetime\"]\n",
    "    df_sum_agg = df_sum_agg.merge(df_max_dt, on=\"customer_id\", how='inner')\n",
    "    df_sum_agg['delta_days'] = (df_sum_agg['max_startdatetime'] - df_sum_agg['startdatetime']) / np.timedelta64(1, 's') / 60 / 60 / 24\n",
    "    \n",
    "    new_ids_cols = list(set(ids_cols).difference([\"startdatetime\"]))\n",
    "    agg_dfs = []\n",
    "    for window in windows:\n",
    "        filtered_df = df_sum_agg[df_sum_agg['delta_days'] < 30]\n",
    "        filtered_df = (\n",
    "            filtered_df\n",
    "            .groupby(new_ids_cols, as_index=False)\n",
    "            .agg({\n",
    "                \"revenue_sum\": [\"max\", \"mean\", \"std\", \"sum\", \"count\"], \n",
    "                \"items_count\": [\"max\", \"mean\", \"std\", \"sum\"], \n",
    "            })\n",
    "        )\n",
    "        filtered_df.columns = new_ids_cols + [\n",
    "            f\"{col}_{agg_func}_{window}d\" for col in [\"revenue_sum\", \"items_count\"]\n",
    "            for agg_func in [\"max\", \"mean\", \"std\", \"sum\", \"count\"]\n",
    "        ][:-1]\n",
    "        agg_dfs.append(filtered_df)\n",
    "    ids_df = df_sum_agg[new_ids_cols].drop_duplicates().reset_index(drop=True)\n",
    "    for temp_df in agg_dfs:\n",
    "        ids_df = ids_df.merge(temp_df, on=new_ids_cols, how='left')\n",
    "    return ids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b66236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_places_features(dataset, ids_cols):\n",
    "    df = dataset.groupby(ids_cols + [\"ownareaall_sqm\"], as_index=True).agg({\"revenue\": [\"sum\", \"count\"]})\n",
    "    df.columns = [\"revenue_sum\", \"items_count\"]\n",
    "    df.reset_index(inplace=True)\n",
    "    new_ids_cols = list(set(ids_cols).difference([\"startdatetime\"]))\n",
    "    df['ownareaall_sqm'] = np.where(df['ownareaall_sqm']==0, df['ownareaall_sqm'].median(), df['ownareaall_sqm'])\n",
    "    df_feat = df.groupby(new_ids_cols, as_index=True).agg({\"ownareaall_sqm\": [\"mean\", \"std\", \"sem\", \"var\"]})\n",
    "    df_feat.columns = [f\"sqm_place_{func}\" for func in [\"mean\", \"std\", \"sem\", \"var\"]]\n",
    "    df_feat.reset_index(inplace=True)\n",
    "    return df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82330ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_features(dataset, ids_cols):\n",
    "    df = dataset.groupby(ids_cols, as_index=True).agg({\"revenue\": [\"sum\", \"count\"]})\n",
    "    df.columns = [\"revenue_sum\", \"items_count\"]\n",
    "    df.reset_index(inplace=True)\n",
    "    df['startdatetime'] = df['startdatetime'].dt.round('min')\n",
    "    df[\"time\"] = df[\"startdatetime\"].dt.to_pydatetime()\n",
    "    df[\"minutes\"] = df[\"time\"].apply(lambda x: x.hour * 60 + x.minute)\n",
    "    new_ids_cols = list(set(ids_cols).difference([\"startdatetime\"]))\n",
    "    df_feat = df.groupby(new_ids_cols, as_index=True).agg({\"minutes\": [\"mean\", \"std\", \"sem\", \"var\"]})\n",
    "    df_feat.columns = [f\"minutes_{func}\" for func in [\"mean\", \"std\", \"sem\", \"var\"]]\n",
    "    df_feat.reset_index(inplace=True)\n",
    "    return df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d9855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_and_hype_dish_df(df, ids_cols):\n",
    "    df['fun'] = np.select(\n",
    "      [ df['dish_name'].str.contains(\"Игрушка\"),\n",
    "          df['dish_name'].str.contains(\"Энергет\"),\n",
    "          df['dish_name'].str.contains(\"Up\"),\n",
    "          df['dish_name'].str.contains(\"Балтика\"),\n",
    "          df['dish_name'].str.contains(\"Сбер\"),\n",
    "          df['dish_name'].str.contains(\"1RUB\"),\n",
    "          df['dish_name'].str.contains(\"А4\"),\n",
    "          df['dish_name'].str.contains(\"Соус\"),\n",
    "          df['dish_name'].str.contains(\"Влажная салфетка\"),\n",
    "          df['dish_name'].str.contains(\"Пиво\"),\n",
    "          df['dish_name'].str.contains(\"GIFT\")\n",
    "        ],\n",
    "     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "      default=0\n",
    "    )\n",
    "\n",
    "    df_sum_agg_fun = df.groupby(ids_cols, as_index=True).agg({\"fun\": [\"sum\"]})\n",
    "    df_sum_agg_fun.columns = [\"fun_sum\"]\n",
    "    df_sum_agg_fun.reset_index(inplace=True)\n",
    "\n",
    "    new_ids_cols = list(set(ids_cols).difference([\"startdatetime\"]))\n",
    "\n",
    "    df_sum_agg_fun_sum = df_sum_agg_fun.groupby(new_ids_cols, as_index=True).agg({\"fun_sum\": [\"mean\", \"sum\", \"std\"]})\n",
    "    df_sum_agg_fun_sum.columns = [\"fun_mean\", \"fun_sum\", \"fun_std\"]\n",
    "    df_sum_agg_fun_sum.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    return df_sum_agg_fun_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e72cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_toilet_df(df, ids_cols):\n",
    "    df['no_toilet'] = np.select([ df['format_name'].str.contains(\"без туалета\"),], [1], default=0)\n",
    "    df['fudcort'] = np.select([ df['format_name'].str.contains(\"Фудкорт\"),], [1], default=0)\n",
    "\n",
    "    df_sum_1 = df.groupby(ids_cols, as_index=True).agg({\"no_toilet\": [\"max\"], \"fudcort\": [\"max\"]})\n",
    "    df_sum_1.columns = [\"no_toilet_\", \"fudcort_\"]\n",
    "    df_sum_1.reset_index(inplace=True)\n",
    "\n",
    "    new_ids_cols = list(set(ids_cols).difference([\"startdatetime\"]))\n",
    "\n",
    "    df_sum_1_a = df_sum_1.groupby(new_ids_cols, as_index=True).agg({\"no_toilet_\": [\"mean\", \"std\", \"max\"], \"fudcort_\": [\"mean\", \"std\", \"max\"]})\n",
    "    df_sum_1_a.columns = [\n",
    "      \"no_toilet_mean\",\n",
    "      \"no_toilet_std\",\n",
    "      \"no_toilet_max\",\n",
    "      \"fudcort_mean\",\n",
    "      \"fudcort_std\",\n",
    "      \"fudcort_max\",\n",
    "      ]\n",
    "    df_sum_1_a.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    return df_sum_1_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "532a6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weekends_df(df, ids_cols):\n",
    "    df['day_of_week_num'] = df['startdatetime'].dt.dayofweek\n",
    "\n",
    "    df_dn = df.groupby(ids_cols, as_index=True).agg({\"day_of_week_num\": [\"max\"]})\n",
    "    df_dn.columns = [\"day_of_week_num_max\"]\n",
    "    df_dn.reset_index(inplace=True)\n",
    "\n",
    "    df_dn['weekends'] = np.select(\n",
    "      [df_dn['day_of_week_num_max'] > 2], [1],\n",
    "      default=0\n",
    "      )\n",
    "\n",
    "    new_ids_cols = list(set(ids_cols).difference([\"startdatetime\"]))\n",
    "\n",
    "    df_dn_median = df_dn.groupby(new_ids_cols, as_index=True).agg({\"day_of_week_num_max\": [\"median\", \"mean\", \"std\"], \"weekends\": [\"median\", \"mean\", \"std\"]})\n",
    "    df_dn_median.columns = [\"dow_median\", \"dow_mean\", \"dow_std\", \"weekends_median\", \"weekends_mean\", \"weekends_std\"]\n",
    "    df_dn_median.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    return df_dn_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab49ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_month_df(df, ids_cols):\n",
    "    df['day_of_month_num'] = df['startdatetime'].dt.day\n",
    "\n",
    "    df_dn = df.groupby(ids_cols, as_index=True).agg({\"day_of_month_num\": [\"max\"]})\n",
    "    df_dn.columns = [\"day_of_month_num_max\"]\n",
    "    df_dn.reset_index(inplace=True)\n",
    "\n",
    "    df_dn['strange'] = np.select(\n",
    "      [(df_dn['day_of_month_num_max'] < 22) & (df_dn['day_of_month_num_max'] > 5)], [1],\n",
    "      default=0\n",
    "      )\n",
    "\n",
    "    new_ids_cols = list(set(ids_cols).difference([\"startdatetime\"]))\n",
    "\n",
    "    df_dn_median = df_dn.groupby(new_ids_cols, as_index=True).agg({\"day_of_month_num_max\": [\"median\", \"mean\", \"std\"], \"strange\": [\"median\", \"mean\", \"std\"]})\n",
    "    df_dn_median.columns = [\"dom_median\", \"dom_mean\", \"dom_std\", \"strange_median\", \"strange_mean\", \"strange_std\"]\n",
    "    df_dn_median.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    return df_dn_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a3a0c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(dataset, ids_cols):\n",
    "    windows = [7, 14, 28]\n",
    "    df_mean_std = calculate_mean_std_feats(dataset, ids_cols)\n",
    "    df_dynamic = calculate_dynamic_receipt_features(dataset, ids_cols)\n",
    "    df_windows = calculate_window_features(dataset, ids_cols, windows)\n",
    "    df_places = calculate_places_features(dataset, ids_cols)\n",
    "    df_time = calculate_time_features(dataset, ids_cols)\n",
    "    \n",
    "    df_hype_dish = create_base_and_hype_dish_df(dataset, ids_cols)\n",
    "    df_toilet = create_toilet_df(dataset, ids_cols)\n",
    "    df_weekends = create_weekends_df(dataset, ids_cols)\n",
    "    df_month = create_month_df(dataset, ids_cols)\n",
    "    \n",
    "    new_ids_cols = list(set(ids_cols).difference([\"startdatetime\"]))\n",
    "    \n",
    "    df_result = df_mean_std.merge(df_dynamic, on=new_ids_cols, how='left')\n",
    "    df_result = df_result.merge(df_windows, on=new_ids_cols, how='left')\n",
    "    df_result = df_result.merge(df_places, on=new_ids_cols, how='left')\n",
    "    df_result = df_result.merge(df_time, on=new_ids_cols, how='left')\n",
    "    df_result = df_result.merge(df_hype_dish, on=new_ids_cols, how='left')\n",
    "    df_result = df_result.merge(df_toilet, on=new_ids_cols, how='left')\n",
    "    df_result = df_result.merge(df_weekends, on=new_ids_cols, how='left')\n",
    "    df_result = df_result.merge(df_month, on=new_ids_cols, how='left')\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e3a8fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_promo_features(dataset, ids_cols, df_test, ids_cols_test):\n",
    "    dataset[\"1rub\"] = dataset[\"dish_name\"].apply(lambda x: \"1RUB\" in x).astype(int)\n",
    "    dataset[\"recommendation\"] = dataset[\"dish_name\"].apply(lambda x: \"up \" in x.lower() or \"lim.\" in x.lower() or \"ord.\" in x.lower()).astype(int)\n",
    "    dataset['clean_dish'] = dataset[\"dish_name\"].apply(lambda x: x.lower().replace(\"1rub.\", \"\").replace(\"up \", \"\").replace(\"lim.\", \"\").replace(\"ord.\", \"\"))\n",
    "    df_dish_sum = dataset.groupby([\"clean_dish\"], as_index=True).agg({\"revenue\": [\"median\"]})\n",
    "    df_dish_sum.columns = [\"price_median\"]\n",
    "    df_dish_sum.reset_index(inplace=True)\n",
    "    \n",
    "    dataset = dataset.merge(df_dish_sum, on='clean_dish', how='left')\n",
    "    dataset[\"promo\"] = (dataset[\"revenue\"] < dataset[\"price_median\"]).astype(int)\n",
    "    \n",
    "    df_sum_agg = dataset.groupby(ids_cols, as_index=True).agg({\"promo\": [\"max\"], \"1rub\": [\"max\"], \"recommendation\": [\"max\"]})\n",
    "    df_sum_agg.columns = [\"was_promo\", \"was_1rub\", \"was_rec\"]\n",
    "    df_sum_agg.reset_index(inplace=True)\n",
    "    \n",
    "    new_ids_cols = list(set(ids_cols).difference([\"startdatetime\"]))\n",
    "    \n",
    "    df_feat = df_sum_agg.groupby(new_ids_cols, as_index=True).agg({\"was_promo\": [\"mean\", \"std\"], \"was_1rub\": [\"mean\", \"std\"], \"was_rec\": [\"mean\", \"std\"]})\n",
    "    df_feat.columns = [f\"{feat}_{func}\" for feat in [\"was_promo\", \"was_1rub\", \"was_rec\"] for func in [\"mean\", \"std\"]]\n",
    "    df_feat.reset_index(inplace=True)\n",
    "    \n",
    "    df_test[\"1rub\"] = df_test[\"dish_name\"].apply(lambda x: \"1RUB\" in x).astype(int)\n",
    "    df_test[\"recommendation\"] = df_test[\"dish_name\"].apply(lambda x: \"up \" in x.lower() or \"lim.\" in x.lower() or \"ord.\" in x.lower()).astype(int)\n",
    "    df_test['clean_dish'] = df_test[\"dish_name\"].apply(lambda x: x.lower().replace(\"1rub.\", \"\").replace(\"up \", \"\").replace(\"lim.\", \"\").replace(\"ord.\", \"\"))\n",
    "    \n",
    "    df_test = df_test.merge(df_dish_sum, on='clean_dish', how='left')\n",
    "    df_test[\"promo\"] = (df_test[\"revenue\"] < df_test[\"price_median\"]).astype(int)\n",
    "    \n",
    "    df_sum_agg_test = df_test.groupby(ids_cols_test, as_index=True).agg({\"promo\": [\"max\"], \"1rub\": [\"max\"], \"recommendation\": [\"max\"]})\n",
    "    df_sum_agg_test.columns = [\"was_promo\", \"was_1rub\", \"was_rec\"]\n",
    "    df_sum_agg_test.reset_index(inplace=True)\n",
    "    \n",
    "    new_ids_cols = list(set(ids_cols_test).difference([\"startdatetime\"]))\n",
    "    \n",
    "    df_feat_test = df_sum_agg_test.groupby(new_ids_cols, as_index=True).agg({\"was_promo\": [\"mean\", \"std\"], \"was_1rub\": [\"mean\", \"std\"], \"was_rec\": [\"mean\", \"std\"]})\n",
    "    df_feat_test.columns = [f\"{feat}_{func}\" for feat in [\"was_promo\", \"was_1rub\", \"was_rec\"] for func in [\"mean\", \"std\"]]\n",
    "    df_feat_test.reset_index(inplace=True)\n",
    "    \n",
    "    return df_feat, df_feat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "222d2a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_92453/4182318229.py:6: FutureWarning: The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "  df[\"time\"] = df[\"startdatetime\"].dt.to_pydatetime()\n"
     ]
    }
   ],
   "source": [
    "df_train_with_feats = get_all_features(df_train, [\"customer_id\", \"buy_post\", \"startdatetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7aeb479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_92453/4182318229.py:6: FutureWarning: The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "  df[\"time\"] = df[\"startdatetime\"].dt.to_pydatetime()\n"
     ]
    }
   ],
   "source": [
    "df_test_with_feats = get_all_features(df_test, [\"customer_id\", \"startdatetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df519605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feat, df_test_feat = calculate_promo_features(df_train, [\"customer_id\", \"buy_post\", \"startdatetime\"], df_test, [\"customer_id\", \"startdatetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8cd1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_feats = pd.read_parquet('../data/4_9_11_features.parquet')\n",
    "additional_feats = pd.read_parquet('../data/train_additional_feats.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "853c7f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_feats_test = pd.read_parquet('../data/test4_9_11_features.parquet')\n",
    "additional_feats_test = pd.read_parquet('../data/test_additional_feats.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9dba7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_with_feats = (\n",
    "    df_train_with_feats.merge(extra_feats, on=[\"customer_id\", \"buy_post\"], how='left')\n",
    "    .merge(df_train_feat, on=[\"customer_id\", \"buy_post\"], how='left')\n",
    "    .merge(additional_feats, on=[\"customer_id\"], how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d78e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_with_feats.to_parquet(\"../data/train_with_feats_v4.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0b62d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_with_feats = (\n",
    "    df_test_with_feats.merge(extra_feats_test, on=[\"customer_id\"], how='left')\n",
    "    .merge(df_test_feat, on=[\"customer_id\"], how='left')\n",
    "    .merge(additional_feats_test, on=[\"customer_id\"], how='left')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc17065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_with_feats.to_parquet(\"../data/test_with_feats_v4.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf6a805c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500000, 110), (112334, 109))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_with_feats.shape, df_test_with_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1529b163",
   "metadata": {},
   "source": [
    "### IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c44c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_information_value(dataset, feats, target_col):\n",
    "    iv_by_feat = {}\n",
    "    temp = dataset.copy()\n",
    "    for feat in feats:\n",
    "        temp[\"quant_range\"] = pd.qcut(\n",
    "            x=temp[feat], q=[0, 0.25, 0.5, 0.75, 1.0], duplicates=\"drop\"\n",
    "        )\n",
    "\n",
    "        bins = {}\n",
    "        for i, bin in enumerate(temp[\"quant_range\"].unique()):\n",
    "            bins[bin] = i\n",
    "\n",
    "        temp[\"bin\"] = temp[\"quant_range\"].apply(lambda x: bins[x])\n",
    "\n",
    "        iv = (\n",
    "            pd.crosstab(temp[\"bin\"], temp[target_col], normalize=\"columns\")\n",
    "            .assign(woe=lambda dfx: np.log(dfx[1] / dfx[0]))\n",
    "            .assign(iv=lambda dfx: np.sum(dfx[\"woe\"] * (dfx[1] - dfx[0])))\n",
    "        )[\"iv\"].unique()[0]\n",
    "\n",
    "        iv_by_feat[feat] = [iv]\n",
    "    df = pd.DataFrame(iv_by_feat).T\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns = [\"feature\", \"IV\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7d1cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = list(set(df_train_with_feats.columns).difference([\"customer_id\", \"buy_post\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7039e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_df = calculate_information_value(df_train_with_feats, feats, \"buy_post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e522a33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>receipt_count</td>\n",
       "      <td>0.430457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>weekends_std</td>\n",
       "      <td>0.243150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>strange_std</td>\n",
       "      <td>0.237534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>dom_std</td>\n",
       "      <td>0.161640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>revenue_sum_count_28d</td>\n",
       "      <td>0.155249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>revenue_sum_count_14d</td>\n",
       "      <td>0.155249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>revenue_sum_count_7d</td>\n",
       "      <td>0.155249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>was_promo_std</td>\n",
       "      <td>0.120205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>fun_sum</td>\n",
       "      <td>0.105191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>dow_std</td>\n",
       "      <td>0.097692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>abs_sum_delta_mean</td>\n",
       "      <td>0.097432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>was_rec_std</td>\n",
       "      <td>0.090511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>items_count_sum_7d</td>\n",
       "      <td>0.088741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>items_count_sum_14d</td>\n",
       "      <td>0.088741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>items_count_sum_28d</td>\n",
       "      <td>0.088741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>strange_mean</td>\n",
       "      <td>0.085361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>sum_delta_mean</td>\n",
       "      <td>0.081003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>dom_mean</td>\n",
       "      <td>0.078925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>count_delta_max</td>\n",
       "      <td>0.078453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>count_delta_mean</td>\n",
       "      <td>0.077059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>sum_delta_max</td>\n",
       "      <td>0.065213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>first_half_min</td>\n",
       "      <td>0.059577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>dom_median</td>\n",
       "      <td>0.057772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>abs_count_delta_mean</td>\n",
       "      <td>0.052973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>weekends_mean</td>\n",
       "      <td>0.049743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>cosine_similarity</td>\n",
       "      <td>0.047049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>revenue_sum_sum_28d</td>\n",
       "      <td>0.043770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>revenue_sum_sum_7d</td>\n",
       "      <td>0.043770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>revenue_sum_sum_14d</td>\n",
       "      <td>0.043770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>minutes_std</td>\n",
       "      <td>0.042768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>minutes_var</td>\n",
       "      <td>0.042768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>count_delta_min</td>\n",
       "      <td>0.037541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>was_promo_mean</td>\n",
       "      <td>0.034826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ratio</td>\n",
       "      <td>0.031495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>sqm_place_sem</td>\n",
       "      <td>0.030976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>minutes_sem</td>\n",
       "      <td>0.030169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>diff</td>\n",
       "      <td>0.027565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>is_burger_std</td>\n",
       "      <td>0.027302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>dow_mean</td>\n",
       "      <td>0.027288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>count_delta_std</td>\n",
       "      <td>0.024725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sum_delta_min</td>\n",
       "      <td>0.021761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>fun_std</td>\n",
       "      <td>0.021617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dow_median</td>\n",
       "      <td>0.019610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>first_half_max</td>\n",
       "      <td>0.017305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>second_half_max</td>\n",
       "      <td>0.016568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>is_drink_std</td>\n",
       "      <td>0.015697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>sqm_place_std</td>\n",
       "      <td>0.014804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>sqm_place_var</td>\n",
       "      <td>0.014804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sum_delta_std</td>\n",
       "      <td>0.013450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>second_half_std</td>\n",
       "      <td>0.012744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>first_half_std</td>\n",
       "      <td>0.012299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>items_count_max_14d</td>\n",
       "      <td>0.012120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>items_count_max_28d</td>\n",
       "      <td>0.012120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>items_count_max_7d</td>\n",
       "      <td>0.012120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is_drink_mean</td>\n",
       "      <td>0.009762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>fun_mean</td>\n",
       "      <td>0.009084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>no_toilet_mean</td>\n",
       "      <td>0.009020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>items_receipt_mean</td>\n",
       "      <td>0.008995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>items_count_mean_14d</td>\n",
       "      <td>0.008940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>items_count_mean_28d</td>\n",
       "      <td>0.008940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>items_count_mean_7d</td>\n",
       "      <td>0.008940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>drink_size_std</td>\n",
       "      <td>0.008098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>strange_median</td>\n",
       "      <td>0.007423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>drink_size_mean</td>\n",
       "      <td>0.006832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>with_toilet_mean</td>\n",
       "      <td>0.006416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>receipt_sum_std</td>\n",
       "      <td>0.006076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>second_half_mean</td>\n",
       "      <td>0.005947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>fudcort_std</td>\n",
       "      <td>0.005781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>revenue_sum_std_28d</td>\n",
       "      <td>0.005667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>revenue_sum_std_14d</td>\n",
       "      <td>0.005667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>revenue_sum_std_7d</td>\n",
       "      <td>0.005667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>no_toilet_std</td>\n",
       "      <td>0.005554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>first_half_mean</td>\n",
       "      <td>0.005550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>countable_mean</td>\n",
       "      <td>0.004882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>items_receipt_mean_std</td>\n",
       "      <td>0.004762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>is_potato_mean</td>\n",
       "      <td>0.004363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>second_half_min</td>\n",
       "      <td>0.003584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>minutes_mean</td>\n",
       "      <td>0.003522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was_rec_mean</td>\n",
       "      <td>0.003347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>is_burger_mean</td>\n",
       "      <td>0.003036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>is_whopper_mean</td>\n",
       "      <td>0.002882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>is_potato_std</td>\n",
       "      <td>0.002854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>sqm_place_mean</td>\n",
       "      <td>0.002517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>countable_std</td>\n",
       "      <td>0.002282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>is_sauce_std</td>\n",
       "      <td>0.001865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>items_count_std_28d</td>\n",
       "      <td>0.001754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>items_count_std_14d</td>\n",
       "      <td>0.001754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>items_count_std_7d</td>\n",
       "      <td>0.001754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>receipt_sum_mean</td>\n",
       "      <td>0.001557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>is_whopper_std</td>\n",
       "      <td>0.001380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>fudcort_mean</td>\n",
       "      <td>0.001048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>revenue_sum_mean_28d</td>\n",
       "      <td>0.000737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>revenue_sum_mean_7d</td>\n",
       "      <td>0.000737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>revenue_sum_mean_14d</td>\n",
       "      <td>0.000737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>food_court_mean</td>\n",
       "      <td>0.000721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>revenue_sum_max_28d</td>\n",
       "      <td>0.000643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>revenue_sum_max_14d</td>\n",
       "      <td>0.000643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>revenue_sum_max_7d</td>\n",
       "      <td>0.000643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>is_sauce_mean</td>\n",
       "      <td>0.000559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>with_toilet_std</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>food_court_std</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>external_area_mean</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weekends_median</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>external_area_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>was_1rub_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>was_1rub_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>fudcort_max</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>no_toilet_max</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature       IV\n",
       "62            receipt_count 0.430457\n",
       "30             weekends_std 0.243150\n",
       "69              strange_std 0.237534\n",
       "47                  dom_std 0.161640\n",
       "65    revenue_sum_count_28d 0.155249\n",
       "1     revenue_sum_count_14d 0.155249\n",
       "3      revenue_sum_count_7d 0.155249\n",
       "35            was_promo_std 0.120205\n",
       "46                  fun_sum 0.105191\n",
       "88                  dow_std 0.097692\n",
       "97       abs_sum_delta_mean 0.097432\n",
       "15              was_rec_std 0.090511\n",
       "14       items_count_sum_7d 0.088741\n",
       "95      items_count_sum_14d 0.088741\n",
       "36      items_count_sum_28d 0.088741\n",
       "42             strange_mean 0.085361\n",
       "84           sum_delta_mean 0.081003\n",
       "72                 dom_mean 0.078925\n",
       "11          count_delta_max 0.078453\n",
       "22         count_delta_mean 0.077059\n",
       "101           sum_delta_max 0.065213\n",
       "61           first_half_min 0.059577\n",
       "76               dom_median 0.057772\n",
       "18     abs_count_delta_mean 0.052973\n",
       "48            weekends_mean 0.049743\n",
       "96        cosine_similarity 0.047049\n",
       "81      revenue_sum_sum_28d 0.043770\n",
       "21       revenue_sum_sum_7d 0.043770\n",
       "68      revenue_sum_sum_14d 0.043770\n",
       "66              minutes_std 0.042768\n",
       "33              minutes_var 0.042768\n",
       "56          count_delta_min 0.037541\n",
       "39           was_promo_mean 0.034826\n",
       "9                     ratio 0.031495\n",
       "54            sqm_place_sem 0.030976\n",
       "75              minutes_sem 0.030169\n",
       "20                     diff 0.027565\n",
       "38            is_burger_std 0.027302\n",
       "52                 dow_mean 0.027288\n",
       "93          count_delta_std 0.024725\n",
       "17            sum_delta_min 0.021761\n",
       "103                 fun_std 0.021617\n",
       "4                dow_median 0.019610\n",
       "63           first_half_max 0.017305\n",
       "53          second_half_max 0.016568\n",
       "32             is_drink_std 0.015697\n",
       "85            sqm_place_std 0.014804\n",
       "98            sqm_place_var 0.014804\n",
       "16            sum_delta_std 0.013450\n",
       "71          second_half_std 0.012744\n",
       "102          first_half_std 0.012299\n",
       "99      items_count_max_14d 0.012120\n",
       "106     items_count_max_28d 0.012120\n",
       "59       items_count_max_7d 0.012120\n",
       "8             is_drink_mean 0.009762\n",
       "60                 fun_mean 0.009084\n",
       "78           no_toilet_mean 0.009020\n",
       "55       items_receipt_mean 0.008995\n",
       "70     items_count_mean_14d 0.008940\n",
       "29     items_count_mean_28d 0.008940\n",
       "24      items_count_mean_7d 0.008940\n",
       "45           drink_size_std 0.008098\n",
       "19           strange_median 0.007423\n",
       "64          drink_size_mean 0.006832\n",
       "91         with_toilet_mean 0.006416\n",
       "25          receipt_sum_std 0.006076\n",
       "89         second_half_mean 0.005947\n",
       "67              fudcort_std 0.005781\n",
       "79      revenue_sum_std_28d 0.005667\n",
       "58      revenue_sum_std_14d 0.005667\n",
       "31       revenue_sum_std_7d 0.005667\n",
       "100           no_toilet_std 0.005554\n",
       "51          first_half_mean 0.005550\n",
       "92           countable_mean 0.004882\n",
       "26   items_receipt_mean_std 0.004762\n",
       "57           is_potato_mean 0.004363\n",
       "105         second_half_min 0.003584\n",
       "12             minutes_mean 0.003522\n",
       "0              was_rec_mean 0.003347\n",
       "13           is_burger_mean 0.003036\n",
       "27          is_whopper_mean 0.002882\n",
       "73            is_potato_std 0.002854\n",
       "104          sqm_place_mean 0.002517\n",
       "94            countable_std 0.002282\n",
       "83             is_sauce_std 0.001865\n",
       "5       items_count_std_28d 0.001754\n",
       "2       items_count_std_14d 0.001754\n",
       "86       items_count_std_7d 0.001754\n",
       "6          receipt_sum_mean 0.001557\n",
       "87           is_whopper_std 0.001380\n",
       "82             fudcort_mean 0.001048\n",
       "74     revenue_sum_mean_28d 0.000737\n",
       "80      revenue_sum_mean_7d 0.000737\n",
       "37     revenue_sum_mean_14d 0.000737\n",
       "49          food_court_mean 0.000721\n",
       "90      revenue_sum_max_28d 0.000643\n",
       "40      revenue_sum_max_14d 0.000643\n",
       "44       revenue_sum_max_7d 0.000643\n",
       "23            is_sauce_mean 0.000559\n",
       "28          with_toilet_std 0.000203\n",
       "41           food_court_std 0.000157\n",
       "10       external_area_mean 0.000011\n",
       "7           weekends_median 0.000000\n",
       "43        external_area_std 0.000000\n",
       "50             was_1rub_std 0.000000\n",
       "34            was_1rub_mean 0.000000\n",
       "77              fudcort_max 0.000000\n",
       "107           no_toilet_max 0.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_df.sort_values(by=\"IV\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd51728d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bc46d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_df.to_csv(\"../data/feature_information_value.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f616a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackaton_venv",
   "language": "python",
   "name": "hackaton_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
